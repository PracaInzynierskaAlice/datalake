spark:
  master:
    image: nowickib/spark-master:latest
  executor:
    image: nowickib/spark-executor:latest

s3:
  endpoint: https://s3p.cloud.cyfronet.pl
  region: eu-central-1 # ignored when using Minio
  bucket: s3a://warehouse
  secret:
    name: s3-creds
    access_key_id: access_key_id
    secret_access_key: secret_access_key

nessie:
  versionStoreType: JDBC
  postgres:
    jdbcUrl: jdbc:postgresql://149.156.10.139:5433/nessie_data
    secret:
      name: nessie-postgres-creds
      username: username
      password: password

airflow:
  airflowVersion: 2.7.1
  images:
    airflow:
      pullPolicy: Always
      repository: pweglik/airflow
      tag: latest
  webserverSecretKeySecretName: airflow-webserver-secret
  webserver:
    startupProbe:
      periodSeconds: 120
    defaultUser:
      username: admin
      password: admin
      role: Public # we need to change password and role manually, setting public here, so default user doesn't have access to everything be default
  dags:
    persistance:
      enabled: false
    gitSync:
      enabled: true
      repo: https://github.com/PracaInzynierskaAlice/datalake.git
      branch: master
      subpath: 'images/airflow/dags'
  postgresql:
    enabled: false #turns off default postgres database
  data:
    metadataSecretName: airflow-metadata-secret
  pgbouncer:
    enabled: true